{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 8740216,
          "sourceType": "datasetVersion",
          "datasetId": 5247437
        }
      ],
      "dockerImageVersionId": 30733,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Tokenizer"
      ],
      "metadata": {
        "id": "KGvBzFebcrb1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-21T01:17:21.486461Z",
          "iopub.execute_input": "2024-06-21T01:17:21.487456Z",
          "iopub.status.idle": "2024-06-21T01:17:21.499038Z",
          "shell.execute_reply.started": "2024-06-21T01:17:21.487413Z",
          "shell.execute_reply": "2024-06-21T01:17:21.497957Z"
        },
        "trusted": true,
        "id": "XgNCWCAwcfa1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create folder if it does not exist\n",
        "\n",
        "folder1 = \"/kaggle/working/checkpoints\"\n",
        "\n",
        "if not os.path.exists(folder1):\n",
        "    os.mkdir(folder1)\n",
        ""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-21T01:17:25.551056Z",
          "iopub.execute_input": "2024-06-21T01:17:25.551422Z",
          "iopub.status.idle": "2024-06-21T01:17:25.556898Z",
          "shell.execute_reply.started": "2024-06-21T01:17:25.551393Z",
          "shell.execute_reply": "2024-06-21T01:17:25.555699Z"
        },
        "trusted": true,
        "id": "h8-oiprqcfa2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Run once\n",
        "\n",
        "from tokenizers import ByteLevelBPETokenizer\n",
        "from tokenizers.implementations import ByteLevelBPETokenizer\n",
        "from tokenizers.processors import BertProcessing\n",
        "\n",
        "train_text = [\"/kaggle/working/words_250000_train.txt\"]\n",
        "\n",
        "# Initialize a tokenizer\n",
        "tokenizer_model = ByteLevelBPETokenizer()\n",
        "\n",
        "# Customize training\n",
        "tokenizer_model.train(files=train_text, vocab_size=261, min_frequency=3, special_tokens=[\"<s>\", \"<pad>\", \"</s>\", \"<unk>\", \"<mask>\"])\n",
        "tokenizer_model.save_model(\"/kaggle/working/checkpoints\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-21T01:17:30.353581Z",
          "iopub.execute_input": "2024-06-21T01:17:30.353986Z",
          "iopub.status.idle": "2024-06-21T01:17:34.583653Z",
          "shell.execute_reply.started": "2024-06-21T01:17:30.353954Z",
          "shell.execute_reply": "2024-06-21T01:17:34.582690Z"
        },
        "trusted": true,
        "id": "EaPQNffEcfa3",
        "outputId": "303bb14f-99fc-4671-d0ec-cf3aecfe185b"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "\n\n\n",
          "output_type": "stream"
        },
        {
          "execution_count": 3,
          "output_type": "execute_result",
          "data": {
            "text/plain": "['/kaggle/working/checkpoints/vocab.json',\n '/kaggle/working/checkpoints/merges.txt']"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_model = ByteLevelBPETokenizer(\n",
        "    \"/kaggle/working/checkpoints/vocab.json\",\n",
        "    \"/kaggle/working/checkpoints/merges.txt\",\n",
        ")\n",
        "\n",
        "tokenizer_model._tokenizer.post_processor = BertProcessing(\n",
        "    (\"</s>\", tokenizer_model.token_to_id(\"</s>\")),\n",
        "    (\"<s>\", tokenizer_model.token_to_id(\"<s>\")),\n",
        ")\n",
        "\n",
        "tokenizer_model.enable_truncation(max_length=128)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-20T22:09:03.273143Z",
          "iopub.execute_input": "2024-06-20T22:09:03.274152Z",
          "iopub.status.idle": "2024-06-20T22:09:03.282334Z",
          "shell.execute_reply.started": "2024-06-20T22:09:03.274105Z",
          "shell.execute_reply": "2024-06-20T22:09:03.281404Z"
        },
        "trusted": true,
        "id": "GTqlrdxkcfa4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_model.encode('hammer').tokens"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-20T22:09:08.313260Z",
          "iopub.execute_input": "2024-06-20T22:09:08.314090Z",
          "iopub.status.idle": "2024-06-20T22:09:08.319971Z",
          "shell.execute_reply.started": "2024-06-20T22:09:08.314056Z",
          "shell.execute_reply": "2024-06-20T22:09:08.319096Z"
        },
        "trusted": true,
        "id": "rRUSSi32cfa4",
        "outputId": "1c0f835d-6691-4dfb-da03-a43d0c9c1a16"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 5,
          "output_type": "execute_result",
          "data": {
            "text/plain": "['<s>', 'h', 'a', 'm', 'm', 'e', 'r', '</s>']"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import RobertaConfig\n",
        "\n",
        "config = RobertaConfig(\n",
        "    vocab_size=261,\n",
        "    max_position_embeddings=128,\n",
        "    num_attention_heads=16,\n",
        "    num_hidden_layers=10,\n",
        "    type_vocab_size=1,)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-20T22:09:19.693164Z",
          "iopub.execute_input": "2024-06-20T22:09:19.693888Z",
          "iopub.status.idle": "2024-06-20T22:09:23.916229Z",
          "shell.execute_reply.started": "2024-06-20T22:09:19.693856Z",
          "shell.execute_reply": "2024-06-20T22:09:23.915462Z"
        },
        "trusted": true,
        "id": "DC7io0DDcfa4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import RobertaTokenizerFast\n",
        "\n",
        "tokenizer = RobertaTokenizerFast.from_pretrained(\"/kaggle/working/checkpoints\", max_len=128)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-20T22:09:27.453332Z",
          "iopub.execute_input": "2024-06-20T22:09:27.453849Z",
          "iopub.status.idle": "2024-06-20T22:09:27.496229Z",
          "shell.execute_reply.started": "2024-06-20T22:09:27.453818Z",
          "shell.execute_reply": "2024-06-20T22:09:27.495393Z"
        },
        "trusted": true,
        "id": "c6yg3e1ccfa4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.save_pretrained(\"/kaggle/working/checkpoints\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-21T00:44:30.023418Z",
          "iopub.execute_input": "2024-06-21T00:44:30.023770Z",
          "iopub.status.idle": "2024-06-21T00:44:30.033724Z",
          "shell.execute_reply.started": "2024-06-21T00:44:30.023741Z",
          "shell.execute_reply": "2024-06-21T00:44:30.032370Z"
        },
        "trusted": true,
        "id": "mxh8F4Picfa4",
        "outputId": "c77f9cda-e794-4d6d-9e05-b2566c6f2144"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 79,
          "output_type": "execute_result",
          "data": {
            "text/plain": "('/kaggle/working/checkpoints/tokenizer_config.json',\n '/kaggle/working/checkpoints/special_tokens_map.json',\n '/kaggle/working/checkpoints/vocab.json',\n '/kaggle/working/checkpoints/merges.txt',\n '/kaggle/working/checkpoints/added_tokens.json',\n '/kaggle/working/checkpoints/tokenizer.json')"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dataset"
      ],
      "metadata": {
        "id": "-MUrknREczr6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import LineByLineTextDataset\n",
        "\n",
        "dataset_for_tokenize = LineByLineTextDataset(\n",
        "    tokenizer=tokenizer,\n",
        "    file_path=\"/kaggle/input/words-data/words_250000_train.txt\",\n",
        "    block_size=128,\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-20T22:09:31.373457Z",
          "iopub.execute_input": "2024-06-20T22:09:31.373785Z",
          "iopub.status.idle": "2024-06-20T22:09:50.468537Z",
          "shell.execute_reply.started": "2024-06-20T22:09:31.373761Z",
          "shell.execute_reply": "2024-06-20T22:09:50.467722Z"
        },
        "trusted": true,
        "id": "U0LemLX1cfa5",
        "outputId": "a184e5be-5adf-417e-f4c9-26692bad609a"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "2024-06-20 22:09:33.575391: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-20 22:09:33.575529: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-20 22:09:33.696291: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/opt/conda/lib/python3.10/site-packages/transformers/data/datasets/language_modeling.py:119: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n  warnings.warn(\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset_for_tokenize[0]) #aaa\n",
        "print(dataset_for_tokenize[42]) #abacterial"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-20T22:09:53.713145Z",
          "iopub.execute_input": "2024-06-20T22:09:53.713779Z",
          "iopub.status.idle": "2024-06-20T22:09:53.738891Z",
          "shell.execute_reply.started": "2024-06-20T22:09:53.713747Z",
          "shell.execute_reply": "2024-06-20T22:09:53.738046Z"
        },
        "trusted": true,
        "id": "i-DTqs0Wcfa5",
        "outputId": "bb4ab077-9134-4360-d45c-05c19e29dad5"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "{'input_ids': tensor([ 0, 69, 69, 69,  2])}\n{'input_ids': tensor([ 0, 69, 70, 69, 71, 88, 73, 86, 77, 69, 80,  2])}\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import DataCollatorForLanguageModeling\n",
        "from transformers import RobertaForMaskedLM\n",
        "from transformers import Trainer, TrainingArguments"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-20T22:09:56.457600Z",
          "iopub.execute_input": "2024-06-20T22:09:56.457991Z",
          "iopub.status.idle": "2024-06-20T22:09:58.186401Z",
          "shell.execute_reply.started": "2024-06-20T22:09:56.457961Z",
          "shell.execute_reply": "2024-06-20T22:09:58.185539Z"
        },
        "trusted": true,
        "id": "N6ViYmq8cfa5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model Training"
      ],
      "metadata": {
        "id": "nVsoYxzOc28y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "device"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-20T22:09:59.853191Z",
          "iopub.execute_input": "2024-06-20T22:09:59.854203Z",
          "iopub.status.idle": "2024-06-20T22:09:59.884297Z",
          "shell.execute_reply.started": "2024-06-20T22:09:59.854167Z",
          "shell.execute_reply": "2024-06-20T22:09:59.883398Z"
        },
        "trusted": true,
        "id": "04b6pPYxcfa5",
        "outputId": "efd02bc6-6587-4c44-bfbd-9473ac955f50"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 11,
          "output_type": "execute_result",
          "data": {
            "text/plain": "device(type='cuda')"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fraction of tokens to mask\n",
        "masking = 0.6"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-20T22:10:02.628416Z",
          "iopub.execute_input": "2024-06-20T22:10:02.629279Z",
          "iopub.status.idle": "2024-06-20T22:10:02.633193Z",
          "shell.execute_reply.started": "2024-06-20T22:10:02.629244Z",
          "shell.execute_reply": "2024-06-20T22:10:02.632220Z"
        },
        "trusted": true,
        "id": "YLlvcJ_7cfa5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RobertaForMaskedLM(config=config)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-20T22:10:08.833092Z",
          "iopub.execute_input": "2024-06-20T22:10:08.833683Z",
          "iopub.status.idle": "2024-06-20T22:10:10.178211Z",
          "shell.execute_reply.started": "2024-06-20T22:10:08.833651Z",
          "shell.execute_reply": "2024-06-20T22:10:10.177160Z"
        },
        "trusted": true,
        "id": "Jq6Ix_Czcfa5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=True, mlm_probability=masking)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-20T22:10:13.153404Z",
          "iopub.execute_input": "2024-06-20T22:10:13.154247Z",
          "iopub.status.idle": "2024-06-20T22:10:13.158678Z",
          "shell.execute_reply.started": "2024-06-20T22:10:13.154210Z",
          "shell.execute_reply": "2024-06-20T22:10:13.157682Z"
        },
        "trusted": true,
        "id": "gyzbzH3scfa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create folder if it does not exist\n",
        "\n",
        "folder1 = f\"/kaggle/working/checkpoints/mlm_{masking}\"\n",
        "\n",
        "if not os.path.exists(folder1):\n",
        "    os.mkdir(folder1)\n",
        ""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-20T22:10:18.943166Z",
          "iopub.execute_input": "2024-06-20T22:10:18.943529Z",
          "iopub.status.idle": "2024-06-20T22:10:18.948576Z",
          "shell.execute_reply.started": "2024-06-20T22:10:18.943499Z",
          "shell.execute_reply": "2024-06-20T22:10:18.947636Z"
        },
        "trusted": true,
        "id": "249U3pOpcfa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create folder if it does not exist\n",
        "\n",
        "folder1 = f\"/kaggle/working/checkpoints/mlm_{masking}/final_checkpoint\"\n",
        "\n",
        "if not os.path.exists(folder1):\n",
        "    os.mkdir(folder1)\n",
        ""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-20T22:10:22.533278Z",
          "iopub.execute_input": "2024-06-20T22:10:22.533970Z",
          "iopub.status.idle": "2024-06-20T22:10:22.538820Z",
          "shell.execute_reply.started": "2024-06-20T22:10:22.533938Z",
          "shell.execute_reply": "2024-06-20T22:10:22.537711Z"
        },
        "trusted": true,
        "id": "zl1w6XZjcfa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=f\"/kaggle/working/checkpoints/mlm_{masking}\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=16,\n",
        "    per_device_train_batch_size=128,\n",
        "    save_strategy='no',\n",
        "    save_total_limit=2,\n",
        "    prediction_loss_only=True,)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=collator,\n",
        "    train_dataset=dataset_for_tokenize,)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-20T22:10:35.713157Z",
          "iopub.execute_input": "2024-06-20T22:10:35.713516Z",
          "iopub.status.idle": "2024-06-20T22:10:36.602119Z",
          "shell.execute_reply.started": "2024-06-20T22:10:35.713486Z",
          "shell.execute_reply": "2024-06-20T22:10:36.601377Z"
        },
        "trusted": true,
        "id": "bj9QbCSncfa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()\n",
        "torch.cuda.empty_cache()\n",
        "trainer.save_model(f\"./checkpoints/mlm_{masking}/final_checkpoint\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-20T22:10:40.853378Z",
          "iopub.execute_input": "2024-06-20T22:10:40.854210Z",
          "iopub.status.idle": "2024-06-20T23:59:34.906461Z",
          "shell.execute_reply.started": "2024-06-20T22:10:40.854177Z",
          "shell.execute_reply": "2024-06-20T23:59:34.905387Z"
        },
        "trusted": true,
        "id": "d3m0maxKcfa6",
        "outputId": "eca105b3-cb1b-4d0c-f60a-ff4d74cfd76f"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:",
          "output_type": "stream"
        },
        {
          "output_type": "stream",
          "name": "stdin",
          "text": "  ········································\n"
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "wandb version 0.17.2 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.17.0"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20240620_221054-zbw5rgqn</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/iitr_ayush/huggingface/runs/zbw5rgqn' target=\"_blank\">/kaggle/working/checkpoints/mlm_0.6</a></strong> to <a href='https://wandb.ai/iitr_ayush/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/iitr_ayush/huggingface' target=\"_blank\">https://wandb.ai/iitr_ayush/huggingface</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/iitr_ayush/huggingface/runs/zbw5rgqn' target=\"_blank\">https://wandb.ai/iitr_ayush/huggingface/runs/zbw5rgqn</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='28416' max='28416' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [28416/28416 1:48:21, Epoch 16/16]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>2.504900</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>2.211900</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>2.136400</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>2.101100</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>2.067800</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>2.047100</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>2.030500</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>2.013000</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>1.998500</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>1.990500</td>\n    </tr>\n    <tr>\n      <td>5500</td>\n      <td>1.980300</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>1.965600</td>\n    </tr>\n    <tr>\n      <td>6500</td>\n      <td>1.962300</td>\n    </tr>\n    <tr>\n      <td>7000</td>\n      <td>1.952500</td>\n    </tr>\n    <tr>\n      <td>7500</td>\n      <td>1.943800</td>\n    </tr>\n    <tr>\n      <td>8000</td>\n      <td>1.935800</td>\n    </tr>\n    <tr>\n      <td>8500</td>\n      <td>1.935500</td>\n    </tr>\n    <tr>\n      <td>9000</td>\n      <td>1.923700</td>\n    </tr>\n    <tr>\n      <td>9500</td>\n      <td>1.918100</td>\n    </tr>\n    <tr>\n      <td>10000</td>\n      <td>1.917300</td>\n    </tr>\n    <tr>\n      <td>10500</td>\n      <td>1.911400</td>\n    </tr>\n    <tr>\n      <td>11000</td>\n      <td>1.907600</td>\n    </tr>\n    <tr>\n      <td>11500</td>\n      <td>1.903100</td>\n    </tr>\n    <tr>\n      <td>12000</td>\n      <td>1.894600</td>\n    </tr>\n    <tr>\n      <td>12500</td>\n      <td>1.895400</td>\n    </tr>\n    <tr>\n      <td>13000</td>\n      <td>1.886000</td>\n    </tr>\n    <tr>\n      <td>13500</td>\n      <td>1.886300</td>\n    </tr>\n    <tr>\n      <td>14000</td>\n      <td>1.879800</td>\n    </tr>\n    <tr>\n      <td>14500</td>\n      <td>1.875100</td>\n    </tr>\n    <tr>\n      <td>15000</td>\n      <td>1.872700</td>\n    </tr>\n    <tr>\n      <td>15500</td>\n      <td>1.870900</td>\n    </tr>\n    <tr>\n      <td>16000</td>\n      <td>1.862600</td>\n    </tr>\n    <tr>\n      <td>16500</td>\n      <td>1.856900</td>\n    </tr>\n    <tr>\n      <td>17000</td>\n      <td>1.858400</td>\n    </tr>\n    <tr>\n      <td>17500</td>\n      <td>1.855600</td>\n    </tr>\n    <tr>\n      <td>18000</td>\n      <td>1.853600</td>\n    </tr>\n    <tr>\n      <td>18500</td>\n      <td>1.847600</td>\n    </tr>\n    <tr>\n      <td>19000</td>\n      <td>1.851200</td>\n    </tr>\n    <tr>\n      <td>19500</td>\n      <td>1.855200</td>\n    </tr>\n    <tr>\n      <td>20000</td>\n      <td>1.839600</td>\n    </tr>\n    <tr>\n      <td>20500</td>\n      <td>1.839100</td>\n    </tr>\n    <tr>\n      <td>21000</td>\n      <td>1.835200</td>\n    </tr>\n    <tr>\n      <td>21500</td>\n      <td>1.843000</td>\n    </tr>\n    <tr>\n      <td>22000</td>\n      <td>1.830800</td>\n    </tr>\n    <tr>\n      <td>22500</td>\n      <td>1.830800</td>\n    </tr>\n    <tr>\n      <td>23000</td>\n      <td>1.830900</td>\n    </tr>\n    <tr>\n      <td>23500</td>\n      <td>1.827300</td>\n    </tr>\n    <tr>\n      <td>24000</td>\n      <td>1.824000</td>\n    </tr>\n    <tr>\n      <td>24500</td>\n      <td>1.829300</td>\n    </tr>\n    <tr>\n      <td>25000</td>\n      <td>1.826300</td>\n    </tr>\n    <tr>\n      <td>25500</td>\n      <td>1.819100</td>\n    </tr>\n    <tr>\n      <td>26000</td>\n      <td>1.820300</td>\n    </tr>\n    <tr>\n      <td>26500</td>\n      <td>1.823200</td>\n    </tr>\n    <tr>\n      <td>27000</td>\n      <td>1.818500</td>\n    </tr>\n    <tr>\n      <td>27500</td>\n      <td>1.812500</td>\n    </tr>\n    <tr>\n      <td>28000</td>\n      <td>1.810300</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sanity Check"
      ],
      "metadata": {
        "id": "0eEyAWqgc7dF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "hangman_guess = pipeline(\"fill-mask\", model=f\"/kaggle/working/checkpoints/mlm_{masking}/final_checkpoint\", tokenizer=\"/kaggle/working/checkpoints\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-21T00:45:59.017784Z",
          "iopub.execute_input": "2024-06-21T00:45:59.018439Z",
          "iopub.status.idle": "2024-06-21T00:45:59.188223Z",
          "shell.execute_reply.started": "2024-06-21T00:45:59.018403Z",
          "shell.execute_reply": "2024-06-21T00:45:59.187177Z"
        },
        "trusted": true,
        "id": "fm3mv-rgcfa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hangman_guess('hamm<mask>r')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-21T00:46:02.532626Z",
          "iopub.execute_input": "2024-06-21T00:46:02.533375Z",
          "iopub.status.idle": "2024-06-21T00:46:02.593819Z",
          "shell.execute_reply.started": "2024-06-21T00:46:02.533311Z",
          "shell.execute_reply": "2024-06-21T00:46:02.592282Z"
        },
        "trusted": true,
        "id": "idnt7afvcfa6",
        "outputId": "582cf083-1d78-48a0-a887-52ff895cc407"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 85,
          "output_type": "execute_result",
          "data": {
            "text/plain": "[{'score': 0.8156739473342896,\n  'token': 73,\n  'token_str': 'e',\n  'sequence': 'hammer'},\n {'score': 0.12053459882736206,\n  'token': 69,\n  'token_str': 'a',\n  'sequence': 'hammar'},\n {'score': 0.0362255796790123,\n  'token': 83,\n  'token_str': 'o',\n  'sequence': 'hammor'},\n {'score': 0.014343079179525375,\n  'token': 77,\n  'token_str': 'i',\n  'sequence': 'hammir'},\n {'score': 0.010892124846577644,\n  'token': 89,\n  'token_str': 'u',\n  'sequence': 'hammur'}]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fill_letter(word, rank, idx=0):\n",
        "    print(word, rank)\n",
        "    guess = hangman_guess(word)[idx][rank]\n",
        "    print(guess)\n",
        "    if guess.get('token') == 1:\n",
        "        return ' '\n",
        "    return guess.get('sequence')\n",
        "\n",
        "fill_letter('ha<mask>m<mask>r',0)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-21T00:46:15.974399Z",
          "iopub.execute_input": "2024-06-21T00:46:15.975203Z",
          "iopub.status.idle": "2024-06-21T00:46:16.037675Z",
          "shell.execute_reply.started": "2024-06-21T00:46:15.975170Z",
          "shell.execute_reply": "2024-06-21T00:46:16.036767Z"
        },
        "trusted": true,
        "id": "TWrsg7chcfa6",
        "outputId": "9efb76b5-4e4d-42ef-82ef-f89a0cb294b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "ha<mask>m<mask>r 0\n{'score': 0.42544108629226685, 'token': 81, 'token_str': 'm', 'sequence': '<s>hamm<mask>r</s>'}\n",
          "output_type": "stream"
        },
        {
          "execution_count": 86,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'<s>hamm<mask>r</s>'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Download directory"
      ],
      "metadata": {
        "id": "jBBqsMOPdELZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(\"/kaggle/working/checkpoints\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-21T00:45:50.427744Z",
          "iopub.execute_input": "2024-06-21T00:45:50.428422Z",
          "iopub.status.idle": "2024-06-21T00:45:50.438052Z",
          "shell.execute_reply.started": "2024-06-21T00:45:50.428388Z",
          "shell.execute_reply": "2024-06-21T00:45:50.436890Z"
        },
        "trusted": true,
        "id": "3GJPKcyMcfa7",
        "outputId": "12271576-cd9f-4237-a215-70d01a308b61"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 83,
          "output_type": "execute_result",
          "data": {
            "text/plain": "['vocab.json',\n 'tokenizer_config.json',\n 'model.safetensors',\n 'special_tokens_map.json',\n 'merges.txt',\n 'mlm_0.6',\n 'tokenizer.json']"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r file.zip /kaggle/working/checkpoints"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-21T00:48:31.400981Z",
          "iopub.execute_input": "2024-06-21T00:48:31.401382Z",
          "iopub.status.idle": "2024-06-21T00:49:02.941072Z",
          "shell.execute_reply.started": "2024-06-21T00:48:31.401351Z",
          "shell.execute_reply": "2024-06-21T00:49:02.939766Z"
        },
        "trusted": true,
        "id": "iWoG1HGucfa7",
        "outputId": "58fa75e5-3031-498f-cc0c-17bd30eea15c"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "updating: kaggle/working/checkpoints/ (stored 0%)\nupdating: kaggle/working/checkpoints/vocab.json (deflated 57%)\nupdating: kaggle/working/checkpoints/merges.txt (stored 0%)\nupdating: kaggle/working/checkpoints/mlm_0.6/ (stored 0%)\nupdating: kaggle/working/checkpoints/mlm_0.6/runs/ (stored 0%)\nupdating: kaggle/working/checkpoints/mlm_0.6/runs/Jun20_22-10-35_9e71dcb8f86e/ (stored 0%)\nupdating: kaggle/working/checkpoints/mlm_0.6/runs/Jun20_22-10-35_9e71dcb8f86e/events.out.tfevents.1718921441.9e71dcb8f86e.34.0 (deflated 65%)\nupdating: kaggle/working/checkpoints/mlm_0.6/final_checkpoint/ (stored 0%)\nupdating: kaggle/working/checkpoints/mlm_0.6/final_checkpoint/model.safetensors (deflated 7%)\nupdating: kaggle/working/checkpoints/mlm_0.6/final_checkpoint/config.json (deflated 49%)\nupdating: kaggle/working/checkpoints/mlm_0.6/final_checkpoint/training_args.bin (deflated 52%)\nupdating: kaggle/working/checkpoints/model.safetensors (deflated 7%)\n  adding: kaggle/working/checkpoints/tokenizer_config.json (deflated 76%)\n  adding: kaggle/working/checkpoints/special_tokens_map.json (deflated 84%)\n  adding: kaggle/working/checkpoints/tokenizer.json (deflated 73%)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-21T00:49:09.322799Z",
          "iopub.execute_input": "2024-06-21T00:49:09.323736Z",
          "iopub.status.idle": "2024-06-21T00:49:10.350608Z",
          "shell.execute_reply.started": "2024-06-21T00:49:09.323698Z",
          "shell.execute_reply": "2024-06-21T00:49:10.349571Z"
        },
        "trusted": true,
        "id": "aLE6_Yb6cfa7",
        "outputId": "338a260b-c5dc-4df0-833a-e66b8d51ec58"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "checkpoints  file.zip  wandb\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import FileLink\n",
        "FileLink(r'file.zip')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-21T00:49:12.471030Z",
          "iopub.execute_input": "2024-06-21T00:49:12.471792Z",
          "iopub.status.idle": "2024-06-21T00:49:12.480447Z",
          "shell.execute_reply.started": "2024-06-21T00:49:12.471752Z",
          "shell.execute_reply": "2024-06-21T00:49:12.479505Z"
        },
        "trusted": true,
        "id": "6wFUIbCCcfa7",
        "outputId": "51bed2fb-aa93-42bc-8bef-8650edd2cedf"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 89,
          "output_type": "execute_result",
          "data": {
            "text/plain": "/kaggle/working/file.zip",
            "text/html": "<a href='file.zip' target='_blank'>file.zip</a><br>"
          },
          "metadata": {}
        }
      ]
    }
  ]
}